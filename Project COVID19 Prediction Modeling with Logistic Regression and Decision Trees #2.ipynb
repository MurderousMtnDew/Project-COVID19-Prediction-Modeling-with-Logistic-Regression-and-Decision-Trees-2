{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project COVID19 Prediction Modeling with Logistic Regression and Decision Trees 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Zachary Wing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark and create a session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setup Complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"CovidDataSets\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "display(\"Setup Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We uploaded the entire model data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Records in File:  2182\n",
      "\n",
      "SCHEMA:\n",
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- Rev_Age: integer (nullable = true)\n",
      " |-- Patient_Contact: integer (nullable = true)\n",
      " |-- Have_Onset_Date: integer (nullable = true)\n",
      " |-- Duration: integer (nullable = true)\n",
      " |-- patient_id: long (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- infection_case: string (nullable = true)\n",
      " |-- infected_by: long (nullable = true)\n",
      " |-- symptom_onset_date: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- confirmed_date: string (nullable = true)\n",
      " |-- released_date: string (nullable = true)\n",
      "\n",
      "\n",
      "DATA FROM CSV FILE:\n",
      "+--------+------+-------+---------------+---------------+--------+----------+-------+--------+------------+--------------------+-----------+------------------+----+--------------+-------------+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|patient_id|country|province|        city|      infection_case|infected_by|symptom_onset_date|_c13|confirmed_date|released_date|\n",
      "+--------+------+-------+---------------+---------------+--------+----------+-------+--------+------------+--------------------+-----------+------------------+----+--------------+-------------+\n",
      "|released|  male|     50|              0|              1|      13|1000000001|  Korea|   Seoul|  Gangseo-gu|     overseas inflow|       null|          01/22/20|null|       1/23/20|       2/5/20|\n",
      "|released|  male|     30|              0|              0|      32|1000000002|  Korea|   Seoul| Jungnang-gu|     overseas inflow|       null|              null|null|       1/30/20|       3/2/20|\n",
      "|released|  male|     50|              1|              0|      20|1000000003|  Korea|   Seoul|   Jongno-gu|contact with patient| 2002000001|              null|null|       1/30/20|      2/19/20|\n",
      "|released|  male|     20|              0|              1|      16|1000000004|  Korea|   Seoul|     Mapo-gu|     overseas inflow|       null|          01/26/20|null|       1/30/20|      2/15/20|\n",
      "|released|female|     20|              1|              0|      24|1000000005|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000002|              null|null|       1/31/20|      2/24/20|\n",
      "|released|female|     50|              1|              0|      19|1000000006|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|              null|null|       1/31/20|      2/19/20|\n",
      "|released|  male|     20|              1|              0|      10|1000000007|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|              null|null|       1/31/20|      2/10/20|\n",
      "|released|  male|     20|              0|              0|      22|1000000008|  Korea|   Seoul|         etc|     overseas inflow|       null|              null|null|        2/2/20|      2/24/20|\n",
      "|released|  male|     30|              0|              0|      16|1000000009|  Korea|   Seoul|   Songpa-gu|     overseas inflow|       null|              null|null|        2/5/20|      2/21/20|\n",
      "|released|female|     60|              1|              0|      24|1000000010|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000003|              null|null|        2/5/20|      2/29/20|\n",
      "|released|female|     50|              0|              0|      23|1000000011|  China|   Seoul|Seodaemun-gu|     overseas inflow|       null|              null|null|        2/6/20|      2/29/20|\n",
      "|released|  male|     20|              0|              0|      20|1000000012|  Korea|   Seoul|         etc|     overseas inflow|       null|              null|null|        2/7/20|      2/27/20|\n",
      "|released|  male|     80|              1|              0|     100|1000000013|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|              null|null|       2/16/20|         null|\n",
      "|released|female|     60|              1|              1|      25|1000000014|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000013|          02/06/20|null|       2/16/20|      3/12/20|\n",
      "|isolated|  male|     70|              0|              1|     100|1000000015|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT|       null|          02/11/20|null|       2/19/20|         null|\n",
      "|released|  male|     70|              1|              0|      21|1000000016|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|              null|null|       2/19/20|      3/11/20|\n",
      "|released|  male|     70|              1|              0|      10|1000000017|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|              null|null|       2/20/20|       3/1/20|\n",
      "|isolated|  male|     20|              0|              0|     100|1000000018|  Korea|   Seoul|         etc|                 etc|       null|              null|null|       2/20/20|         null|\n",
      "|released|female|     70|              1|              0|      17|1000000019|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000021|              null|null|       2/20/20|       3/8/20|\n",
      "|isolated|female|     70|              0|              0|     100|1000000020|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT| 1000000015|              null|null|       2/20/20|         null|\n",
      "+--------+------+-------+---------------+---------------+--------+----------+-------+--------+------------+--------------------+-----------+------------------+----+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "#\n",
    "# Read in the data file and show the schema.   This is the file with the 10,000 recrods.  \n",
    "# ADJUST PATH AND FILE NAME APPROPRIATELY FOR YOUR TESTING \n",
    "# \n",
    "\n",
    "bInput = spark.read.format(\"csv\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".option(\"inferSchema\",\"true\")\\\n",
    ".load(\"Model_Data.csv\")\n",
    "\n",
    "print(\"Count of Records in File:  \" + str(bInput.count()))\n",
    "print()\n",
    "print(\"SCHEMA:\")\n",
    "bInput.printSchema()\n",
    "print()\n",
    "print(\"DATA FROM CSV FILE:\")\n",
    "bInput.show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Chose to use the same columns that we used in Project 2 but we also kept 'province' and 'confirmed_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Records in File:  2182\n",
      "\n",
      "SCHEMA:\n",
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- Rev_Age: integer (nullable = true)\n",
      " |-- Patient_Contact: integer (nullable = true)\n",
      " |-- Have_Onset_Date: integer (nullable = true)\n",
      " |-- Duration: integer (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- confirmed_date: string (nullable = true)\n",
      "\n",
      "\n",
      "DATA FROM CSV FILE:\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|province|confirmed_date|\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+\n",
      "|released|  male|     50|              0|              1|      13|   Seoul|       1/23/20|\n",
      "|released|  male|     30|              0|              0|      32|   Seoul|       1/30/20|\n",
      "|released|  male|     50|              1|              0|      20|   Seoul|       1/30/20|\n",
      "|released|  male|     20|              0|              1|      16|   Seoul|       1/30/20|\n",
      "|released|female|     20|              1|              0|      24|   Seoul|       1/31/20|\n",
      "|released|female|     50|              1|              0|      19|   Seoul|       1/31/20|\n",
      "|released|  male|     20|              1|              0|      10|   Seoul|       1/31/20|\n",
      "|released|  male|     20|              0|              0|      22|   Seoul|        2/2/20|\n",
      "|released|  male|     30|              0|              0|      16|   Seoul|        2/5/20|\n",
      "|released|female|     60|              1|              0|      24|   Seoul|        2/5/20|\n",
      "|released|female|     50|              0|              0|      23|   Seoul|        2/6/20|\n",
      "|released|  male|     20|              0|              0|      20|   Seoul|        2/7/20|\n",
      "|released|  male|     80|              1|              0|     100|   Seoul|       2/16/20|\n",
      "|released|female|     60|              1|              1|      25|   Seoul|       2/16/20|\n",
      "|isolated|  male|     70|              0|              1|     100|   Seoul|       2/19/20|\n",
      "|released|  male|     70|              1|              0|      21|   Seoul|       2/19/20|\n",
      "|released|  male|     70|              1|              0|      10|   Seoul|       2/20/20|\n",
      "|isolated|  male|     20|              0|              0|     100|   Seoul|       2/20/20|\n",
      "|released|female|     70|              1|              0|      17|   Seoul|       2/20/20|\n",
      "|isolated|female|     70|              0|              0|     100|   Seoul|       2/20/20|\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covid = bInput.select('state', 'sex', 'Rev_Age', 'Patient_Contact', 'Have_Onset_Date', 'Duration', 'province', 'confirmed_date')\n",
    "\n",
    "\n",
    "print(\"Count of Records in File:  \" + str(covid.count()))\n",
    "print()\n",
    "print(\"SCHEMA:\")\n",
    "covid.printSchema()\n",
    "print()\n",
    "print(\"DATA FROM CSV FILE:\")\n",
    "covid.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA AFTER FITTING:\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+--------------------+-----+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|province|confirmed_date|            features|label|\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+--------------------+-----+\n",
      "|released|  male|     50|              0|              1|      13|   Seoul|       1/23/20|(85,[1,3,4,6,82],...|  1.0|\n",
      "|released|  male|     30|              0|              0|      32|   Seoul|       1/30/20|(85,[1,4,6,75],[3...|  1.0|\n",
      "|released|  male|     50|              1|              0|      20|   Seoul|       1/30/20|(85,[1,2,4,6,75],...|  1.0|\n",
      "|released|  male|     20|              0|              1|      16|   Seoul|       1/30/20|(85,[1,3,4,6,75],...|  1.0|\n",
      "|released|female|     20|              1|              0|      24|   Seoul|       1/31/20|(85,[0,1,2,4,6,72...|  1.0|\n",
      "|released|female|     50|              1|              0|      19|   Seoul|       1/31/20|(85,[0,1,2,4,6,72...|  1.0|\n",
      "|released|  male|     20|              1|              0|      10|   Seoul|       1/31/20|(85,[1,2,4,6,72],...|  1.0|\n",
      "|released|  male|     20|              0|              0|      22|   Seoul|        2/2/20|(85,[1,4,6,73],[2...|  1.0|\n",
      "|released|  male|     30|              0|              0|      16|   Seoul|        2/5/20|(85,[1,4,6,71],[3...|  1.0|\n",
      "|released|female|     60|              1|              0|      24|   Seoul|        2/5/20|(85,[0,1,2,4,6,71...|  1.0|\n",
      "|released|female|     50|              0|              0|      23|   Seoul|        2/6/20|(85,[0,1,4,6,77],...|  1.0|\n",
      "|released|  male|     20|              0|              0|      20|   Seoul|        2/7/20|(85,[1,4,6,83],[2...|  1.0|\n",
      "|released|  male|     80|              1|              0|     100|   Seoul|       2/16/20|(85,[1,2,4,6,76],...|  1.0|\n",
      "|released|female|     60|              1|              1|      25|   Seoul|       2/16/20|(85,[0,1,2,3,4,6,...|  1.0|\n",
      "|isolated|  male|     70|              0|              1|     100|   Seoul|       2/19/20|(85,[1,3,4,6,67],...|  0.0|\n",
      "|released|  male|     70|              1|              0|      21|   Seoul|       2/19/20|(85,[1,2,4,6,67],...|  1.0|\n",
      "|released|  male|     70|              1|              0|      10|   Seoul|       2/20/20|(85,[1,2,4,6,65],...|  1.0|\n",
      "|isolated|  male|     20|              0|              0|     100|   Seoul|       2/20/20|(85,[1,4,6,65],[2...|  0.0|\n",
      "|released|female|     70|              1|              0|      17|   Seoul|       2/20/20|(85,[0,1,2,4,6,65...|  1.0|\n",
      "|isolated|female|     70|              0|              0|     100|   Seoul|       2/20/20|(85,[0,1,4,6,65],...|  0.0|\n",
      "|released|  male|     80|              1|              0|      17|   Seoul|       2/20/20|(85,[1,2,4,6,65],...|  1.0|\n",
      "|isolated|  male|     30|              0|              0|     100|   Seoul|       2/21/20|(85,[1,4,6,61],[3...|  0.0|\n",
      "|isolated|  male|     50|              0|              0|     100|   Seoul|       2/21/20|(85,[1,4,6,61],[5...|  0.0|\n",
      "|released|  male|     40|              1|              0|      21|   Seoul|       2/22/20|(85,[1,2,4,6,45],...|  1.0|\n",
      "|isolated|  male|     60|              0|              0|     100|   Seoul|       2/22/20|(85,[1,4,6,45],[6...|  0.0|\n",
      "|released|  male|     30|              0|              1|      18|   Seoul|       2/22/20|(85,[1,3,4,6,45],...|  1.0|\n",
      "|released|  male|     50|              0|              0|      10|   Seoul|       2/23/20|(85,[1,4,6,36],[5...|  1.0|\n",
      "|released|female|     70|              0|              0|      17|   Seoul|       2/23/20|(85,[0,1,4,6,36],...|  1.0|\n",
      "|released|female|     20|              0|              1|      14|   Seoul|       2/26/20|(85,[0,1,3,4,6,24...|  1.0|\n",
      "|released|  male|     60|              0|              0|     100|   Seoul|       2/23/20|(85,[1,4,6,36],[6...|  1.0|\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+--------------------+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "# This sets up the data to run through the model.   \n",
    "# The columns \"features\" and \"label\" are added to the existing data set.\n",
    "# These columns provide the data (vectors and label) needed for processing the data\n",
    "# \n",
    "\n",
    "supervised = RFormula(formula=\"state ~ .\")\n",
    "fittedRF = supervised.fit(covid)\n",
    "preparedDF = fittedRF.transform(covid)\n",
    "print()\n",
    "print(\"DATA AFTER FITTING:\")\n",
    "preparedDF.show(30)\n",
    "\n",
    "# \n",
    "# Split the data into a Training set (70%) and Test data (30%)\n",
    "# Set up and run the logistic regression \n",
    "# \n",
    "\n",
    "trainingData, testData = preparedDF.randomSplit([0.7, 0.3], 5) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients = [0.6399410029122297,-0.026502610142830767,-0.25027579284135754,-1.3815530458879628,-0.8758197453866059,12.38603277702386,32.1073625495697,29.37853438754243,13.647003700722081,37.13405239429356,36.540725054458456,9.954329982025738,18.12704093924284,10.025977413810292,12.860227703273523,25.6951459771725,34.470600184287846,19.724014541023077,12.536718153211323,33.18894393942711,3.134306765652094,32.48399409906083,34.78487918870409,35.66298523256887,35.54711344163335,3.3484749083453615,3.175936314276228,35.188326343046064,37.722663646194796,18.31106670249446,35.84423183352662,36.95022145768533,17.81642885551227,-7.214129454721088,35.16761026794457,0.5759549107195292,37.240671648312514,13.284450339490384,33.12332365238555,-8.021837275863529,15.624423556430612,-6.461836068739912,12.18777441942133,34.411852168266506,-5.740128907094946,34.426747180355726,8.356052200876544,37.27158308644432,-5.496925834055324,8.48517520997022,34.08307900676792,-4.659920371356337,34.380335249331274,35.83598498454124,6.67185878280555,19.077220792984345,9.177256257018243,-15.180147994933272,12.292711077473115,13.298245153530814,15.594942362392795,31.276205467987907,-9.440280461799658,9.480605331690288,-5.092895869495047,35.30133007058058,-6.445909943775158,24.885554130670368,-5.591124976492438,21.988157651913077,-16.570393112605974,51.45872812600609,50.14984095680162,56.0907620655689,31.207878498253848,49.56326884080546,72.9851022099006,42.945406016771,41.85926274007652,0.0,0.0,51.30456516861077,48.1695511596146,45.39541757351504,52.70753783744135]\n",
      "Y intercept = 19.146833799031686\n",
      "\n",
      "areaUnderROC: 0.9988061127029608\n",
      "\n",
      "ROC Values\n",
      "+--------------------+------------------+\n",
      "|                 FPR|               TPR|\n",
      "+--------------------+------------------+\n",
      "|                 0.0|               0.0|\n",
      "|                 0.0|0.7370689655172413|\n",
      "|                 0.0|0.7564655172413793|\n",
      "|                 0.0|0.7758620689655172|\n",
      "|                 0.0|0.8038793103448276|\n",
      "|9.551098376313276E-4|0.8362068965517241|\n",
      "|9.551098376313276E-4|0.8577586206896551|\n",
      "|9.551098376313276E-4|0.8793103448275862|\n",
      "|9.551098376313276E-4|0.8987068965517241|\n",
      "|0.001910219675262...|0.9181034482758621|\n",
      "|0.002865329512893...|0.9396551724137931|\n",
      "|0.003820439350525...|0.9568965517241379|\n",
      "|0.007640878701050621|0.9676724137931034|\n",
      "|0.011461318051575931| 0.978448275862069|\n",
      "|0.018147086914995225|0.9827586206896551|\n",
      "|0.025787965616045846|0.9870689655172413|\n",
      "|0.030563514804202482|0.9956896551724138|\n",
      "|0.041069723018147083|0.9956896551724138|\n",
      "| 0.05253104106972302|0.9956896551724138|\n",
      "| 0.06208213944603629|0.9956896551724138|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lrModel = lr.fit(trainingData)\n",
    "displaySummary = lrModel.summary\n",
    "\n",
    "#\n",
    "# To get the parameters associated with the model, un-comment the \"explainParams\" below. \n",
    "# \n",
    "# print(lr.explainParams())\n",
    "\n",
    "#\n",
    "# Get the resulting coefficients and Y intercept \n",
    "# \n",
    "\n",
    "print (\"Coefficients = \" + str(lrModel.coefficients))\n",
    "print (\"Y intercept = \" + str(lrModel.intercept)) \n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "#\n",
    "# Obtain the ROC using the \"AREA UNDER THE CURVE\"\n",
    "# \n",
    "print(\"\")\n",
    "print(\"areaUnderROC: \" + str(displaySummary.areaUnderROC))\n",
    "print(\"\")\n",
    "print('ROC Values')\n",
    "displaySummary.roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION Cross Validation with TEST Data\n",
    "\n",
    "Now we will run the Logistic Regression with the Test data set and review the evaluation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+---------------+---------------+--------+-----------------+--------------+--------------------+-----+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|         province|confirmed_date|            features|label|\n",
      "+--------+------+-------+---------------+---------------+--------+-----------------+--------------+--------------------+-----+\n",
      "|isolated|female|      0|              1|              1|     100|            Seoul|        3/8/20|(85,[0,2,3,4,6,55...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|          Daejeon|       3/30/20|(85,[0,1,4,14,43]...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|          Gwangju|       3/31/20|(85,[0,1,4,17,25]...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|      Gyeonggi-do|       3/26/20|(85,[0,1,4,5,44],...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|            Seoul|       3/23/20|(85,[0,1,4,6,63],...|  0.0|\n",
      "|isolated|female|     10|              0|              1|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,3,4,7,24...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|       2/29/20|(85,[0,1,2,4,5,28...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|       3/10/20|(85,[0,1,2,4,5,21...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|       3/15/20|(85,[0,1,2,4,5,57...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|        3/3/20|(85,[0,1,2,4,5,47...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|        3/4/20|(85,[0,1,2,4,5,38...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|        3/6/20|(85,[0,1,2,4,5,30...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100| Gyeongsangbuk-do|       3/29/20|(85,[0,1,2,4,7,39...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|            Seoul|        3/4/20|(85,[0,1,2,4,6,38...|  0.0|\n",
      "|isolated|female|     10|              1|              1|     100|            Seoul|       3/15/20|(85,[0,1,2,3,4,6,...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Busan|       3/18/20|(85,[0,1,4,9,35],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       Gangwon-do|        3/8/20|(85,[0,1,4,16,55]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|      Gyeonggi-do|       3/28/20|(85,[0,1,4,5,26],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|      Gyeonggi-do|        3/6/20|(85,[0,1,4,5,30],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|      Gyeonggi-do|        4/1/20|(85,[0,1,4,5,48],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,4,7,24],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,4,7,24],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       2/29/20|(85,[0,1,4,7,28],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       3/18/20|(85,[0,1,4,7,35],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       3/30/20|(85,[0,1,4,7,43],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|        3/4/20|(85,[0,1,4,7,38],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangnam-do|       2/24/20|(85,[0,1,4,10,53]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|          Incheon|       3/25/20|(85,[0,1,4,11,46]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|          Incheon|       3/27/20|(85,[0,1,4,11,41]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|          Incheon|        4/3/20|(85,[0,1,4,11,62]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|     Jeollabuk-do|       3/28/20|(85,[0,1,4,18,26]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|     Jeollabuk-do|       3/29/20|(85,[0,1,4,18,39]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/10/20|(85,[0,1,4,6,21],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/10/20|(85,[0,1,4,6,21],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/11/20|(85,[0,1,4,6,42],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/11/20|(85,[0,1,4,6,42],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/17/20|(85,[0,1,4,6,54],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/23/20|(85,[0,1,4,6,63],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/24/20|(85,[0,1,4,6,33],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/25/20|(85,[0,1,4,6,46],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/28/20|(85,[0,1,4,6,26],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/29/20|(85,[0,1,4,6,39],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/29/20|(85,[0,1,4,6,39],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/30/20|(85,[0,1,4,6,43],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/31/20|(85,[0,1,4,6,25],...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Busan|       3/31/20|(85,[0,1,3,4,9,25...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|       3/22/20|(85,[0,1,3,4,5,59...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|       3/30/20|(85,[0,1,3,4,5,43...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|       3/31/20|(85,[0,1,3,4,5,25...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|        4/4/20|(85,[0,1,3,4,5,64...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       2/28/20|(85,[0,1,3,4,6,22...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       3/11/20|(85,[0,1,3,4,6,42...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       3/13/20|(85,[0,1,3,4,6,58...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       3/25/20|(85,[0,1,3,4,6,46...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|        3/8/20|(85,[0,1,3,4,6,55...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/10/20|(85,[0,1,2,4,5,21...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/14/20|(85,[0,1,2,4,5,60...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/16/20|(85,[0,1,2,4,5,37...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/16/20|(85,[0,1,2,4,5,37...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/16/20|(85,[0,1,2,4,5,37...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/24/20|(85,[0,1,2,4,5,33...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/31/20|(85,[0,1,2,4,5,25...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|        4/4/20|(85,[0,1,2,4,5,64...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       2/23/20|(85,[0,1,2,4,7,36...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       2/28/20|(85,[0,1,2,4,7,22...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       2/29/20|(85,[0,1,2,4,7,28...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       3/29/20|(85,[0,1,2,4,7,39...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|        3/5/20|(85,[0,1,2,4,7,34...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|        3/6/20|(85,[0,1,2,4,7,30...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|            Seoul|       3/10/20|(85,[0,1,2,4,6,21...|  0.0|\n",
      "|isolated|female|     20|              1|              1|     100|      Gyeonggi-do|       3/23/20|(85,[0,1,2,3,4,5,...|  0.0|\n",
      "|isolated|female|     20|              1|              1|     100|      Gyeonggi-do|       3/26/20|(85,[0,1,2,3,4,5,...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|Chungcheongnam-do|       3/19/20|(85,[0,1,4,8,40],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|       3/28/20|(85,[0,1,4,5,26],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|       3/30/20|(85,[0,1,4,5,43],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|        3/6/20|(85,[0,1,4,5,30],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|        3/9/20|(85,[0,1,4,5,29],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|       2/25/20|(85,[0,1,4,7,31],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,4,7,24],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|        3/2/20|(85,[0,1,4,7,56],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|       3/30/20|(85,[0,1,4,7,43],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|          Incheon|       3/28/20|(85,[0,1,4,11,26]...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|        3/1/20|(85,[0,1,4,6,27],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/10/20|(85,[0,1,4,6,21],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/19/20|(85,[0,1,4,6,40],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/27/20|(85,[0,1,4,6,41],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/31/20|(85,[0,1,4,6,25],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|        3/9/20|(85,[0,1,4,6,29],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|        4/1/20|(85,[0,1,4,6,48],...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|Chungcheongnam-do|       2/27/20|(85,[0,1,3,4,8,23...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|      Gyeonggi-do|       3/19/20|(85,[0,1,3,4,5,40...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|      Gyeonggi-do|       3/27/20|(85,[0,1,3,4,5,41...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100| Gyeongsangnam-do|       3/31/20|(85,[0,1,3,4,10,2...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|           Sejong|       3/12/20|(85,[0,1,3,4,12,5...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|       2/28/20|(85,[0,1,2,4,5,22...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|       3/15/20|(85,[0,1,2,4,5,57...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|       3/20/20|(85,[0,1,2,4,5,32...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|        4/2/20|(85,[0,1,2,4,5,51...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|        4/3/20|(85,[0,1,2,4,5,62...|  0.0|\n",
      "|isolated|female|     40|              0|              0|     100|Chungcheongbuk-do|       3/13/20|(85,[0,1,4,13,58]...|  0.0|\n",
      "+--------+------+-------+---------------+---------------+--------+-----------------+--------------+--------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+---------------+---------------+--------+----------------+--------------+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|        province|confirmed_date|\n",
      "+--------+------+-------+---------------+---------------+--------+----------------+--------------+\n",
      "|isolated|female|      0|              1|              1|     100|           Seoul|        3/8/20|\n",
      "|isolated|female|     10|              0|              0|     100|         Daejeon|       3/30/20|\n",
      "|isolated|female|     10|              0|              0|     100|         Gwangju|       3/31/20|\n",
      "|isolated|female|     10|              0|              0|     100|     Gyeonggi-do|       3/26/20|\n",
      "|isolated|female|     10|              0|              0|     100|           Seoul|       3/23/20|\n",
      "|isolated|female|     10|              0|              1|     100|Gyeongsangbuk-do|       2/26/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|       2/29/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|       3/10/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|       3/15/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|        3/3/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|        3/4/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|        3/6/20|\n",
      "|isolated|female|     10|              1|              0|     100|Gyeongsangbuk-do|       3/29/20|\n",
      "|isolated|female|     10|              1|              0|     100|           Seoul|        3/4/20|\n",
      "|isolated|female|     10|              1|              1|     100|           Seoul|       3/15/20|\n",
      "|isolated|female|     20|              0|              0|     100|           Busan|       3/18/20|\n",
      "|isolated|female|     20|              0|              0|     100|      Gangwon-do|        3/8/20|\n",
      "|isolated|female|     20|              0|              0|     100|     Gyeonggi-do|       3/28/20|\n",
      "|isolated|female|     20|              0|              0|     100|     Gyeonggi-do|        3/6/20|\n",
      "|isolated|female|     20|              0|              0|     100|     Gyeonggi-do|        4/1/20|\n",
      "+--------+------+-------+---------------+---------------+--------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# RUN THE TEST DATA \n",
    "# \n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "testData.show(100)\n",
    "predictions = lrModel.transform(testData)\n",
    "testDF = predictions\n",
    "\n",
    "#\n",
    "# Create the testDF for output to a CSV file for later comparison. \n",
    "#\n",
    "testDF = testDF.select(\"state\", \"sex\", \"Rev_Age\", \"Patient_Contact\", \"Have_Onset_Date\", \"Duration\", \"province\", 'confirmed_date')\n",
    "\n",
    "testDF.show()\n",
    "\n",
    "#\n",
    "# Create an Evaluator for binary classification, which expects two input columns: rawPrediction and label.\n",
    "# Evaluates predictions and returns a scalar metric areaUnderROC(larger is better but < 1).\n",
    "#\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\\\n",
    "  .setLabelCol(\"label\")\\\n",
    "  .setRawPredictionCol(\"rawPrediction\")\\\n",
    "  .setMetricName(\"areaUnderROC\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truePos =  190\n",
      "falsePos =  10\n",
      "trueNeg =  466\n",
      "falseNeg =  5\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                   Predicted\n",
      "                Y=1    |   Y=0\n",
      " Actual   y=1   190        5\n",
      "          y=0   10         466\n",
      "Test Error = 0.0223547 \n",
      "Accuracy = 0.977645 \n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "#print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "#print(\"Accuracy = %g \" % accuracy)\n",
    "\n",
    "\n",
    "#\n",
    "# Obtain data to build Confusion Matrix \n",
    "#\n",
    "\n",
    "truePos = predictions.select(\"state\").where(\"state = 'released' AND prediction = 1\").count()\n",
    "falsePos = predictions.select(\"state\").where(\"state = 'isolated' AND prediction = 1\").count()\n",
    "trueNeg = predictions.select(\"state\").where(\"state = 'isolated' AND prediction = 0\").count()\n",
    "falseNeg = predictions.select(\"state\").where(\"state = 'released' AND prediction = 0\").count()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"truePos = \", truePos )\n",
    "print(\"falsePos = \", falsePos )\n",
    "print(\"trueNeg = \", trueNeg )\n",
    "print(\"falseNeg = \", falseNeg)\n",
    "\n",
    "print() \n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"                   Predicted\")\n",
    "print(\"                Y=1    |   Y=0\")\n",
    "print(\" Actual   y=1   \" + str(truePos) + \"        \" + str(falseNeg))\n",
    "print(\"          y=0   \" + str(falsePos) + \"         \" + str(trueNeg)) \n",
    "\n",
    "#\n",
    "# To get the parameters associated with the model, un-comment the \"explainParams\" below. \n",
    "# \n",
    "# print(lr.explainParams())\n",
    "\n",
    "\n",
    "print(\"Test Error = %g \" % ((falsePos+falseNeg)/(falsePos+falseNeg+truePos+trueNeg)))\n",
    "print(\"Accuracy = %g \" % ((truePos+trueNeg)/(falsePos+falseNeg+truePos+trueNeg)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCISION TREE - Test Data \n",
    "The actual execution of the Decision Tree model is relatively straightforward.   There is a little prep required for the data so that we will have a label and vectors **indexed**.  \n",
    "* Similar to Logistic Regresion, the data is read in and the \"label\" and \"features\" columns are created. \n",
    "* The data is then converted into Indexes needed for the Decision Tree model to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREDICTIONS DATA:\n",
      "+--------+------+-------+---------------+---------------+--------+----------+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|prediction|\n",
      "+--------+------+-------+---------------+---------------+--------+----------+\n",
      "|isolated|female|      0|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              1|              0|     100|       0.0|\n",
      "|isolated|female|     10|              1|              1|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "+--------+------+-------+---------------+---------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(preparedDF)\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(preparedDF)\n",
    "(trainingDataDT, testDataDT) = preparedDF.randomSplit([0.7, 0.3])\n",
    "\n",
    "# print(\"AFTER INDEXING:\")\n",
    "#\n",
    "# Create a decision tree classifier that will process the columns created above and run the model. \n",
    "# \n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "modelDT = pipeline.fit(trainingDataDT)\n",
    "\n",
    "# Make predictions.\n",
    "predictionsDT = modelDT.transform(testDataDT)\n",
    "\n",
    "print()\n",
    "print(\"PREDICTIONS DATA:\")\n",
    "#predictions.select('sex', 'Rev_Age', 'Patient_Contact', 'Have_Onset_Date', 'Duration', 'rawPrediction', 'prediction', 'probability').show()\n",
    "\n",
    "testDFdt = predictionsDT.select(\"state\", \"sex\", \"Rev_Age\", \"Patient_Contact\", \"Have_Onset_Date\", \"Duration\", \"prediction\")\n",
    "testDFdt.show()\n",
    "\n",
    "\n",
    "testDFdt.write.format(\"csv\").mode('overwrite')\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".save(\"decision_tree_dataframe.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truePos =  194\n",
      "falsePos =  4\n",
      "trueNeg =  431\n",
      "falseNeg =  25\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                   Predicted\n",
      "                Y=1    |   Y=0\n",
      " Actual   y=1   194        25\n",
      "          y=0   4         431\n",
      "Test Error = 0.0443425 \n",
      "Accuracy = 0.955657 \n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsDT)\n",
    "#print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "#print(\"Accuracy = %g \" % accuracy)\n",
    "\n",
    "truePosDT = predictionsDT.select(\"state\").where(\"state = 'released' AND prediction = 1\").count()\n",
    "falsePosDT = predictionsDT.select(\"state\").where(\"state = 'isolated' AND prediction = 1\").count()\n",
    "trueNegDT = predictionsDT.select(\"state\").where(\"state = 'isolated' AND prediction = 0\").count()\n",
    "falseNegDT = predictionsDT.select(\"state\").where(\"state = 'released' AND prediction = 0\").count()\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"truePos = \", truePosDT )\n",
    "print(\"falsePos = \", falsePosDT )\n",
    "print(\"trueNeg = \", trueNegDT )\n",
    "print(\"falseNeg = \", falseNegDT)\n",
    "\n",
    "print() \n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"                   Predicted\")\n",
    "print(\"                Y=1    |   Y=0\")\n",
    "print(\" Actual   y=1   \" + str(truePosDT) + \"        \" + str(falseNegDT))\n",
    "print(\"          y=0   \" + str(falsePosDT) + \"         \" + str(trueNegDT)) \n",
    "\n",
    "\n",
    "print(\"Test Error = %g \" % ((falsePosDT+falseNegDT)/(falsePosDT+falseNegDT+truePosDT+trueNegDT)))\n",
    "print(\"Accuracy = %g \" % ((truePosDT+trueNegDT)/(falsePosDT+falseNegDT+truePosDT+trueNegDT)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion Part 1 Comparison to Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the exact same calculations as I did in Project 2 of Logistic Regression and Decision Tree. However, I add the province and the confirmed sick date to this dataset. Both the Logistic Regression and the Decision Tree for this dataset had a higher accuracy and lower error in predictions. In this data set the Logistic Regression was more accurate than the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this seciton we are going to switch the response variable from the 'state' to the 'sex' of the patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA AFTER FITTING:\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+--------------------+-----+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|province|confirmed_date|            features|label|\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+--------------------+-----+\n",
      "|released|  male|     50|              0|              1|      13|   Seoul|       1/23/20|(85,[1,3,4,6,82],...|  1.0|\n",
      "|released|  male|     30|              0|              0|      32|   Seoul|       1/30/20|(85,[1,4,6,75],[3...|  1.0|\n",
      "|released|  male|     50|              1|              0|      20|   Seoul|       1/30/20|(85,[1,2,4,6,75],...|  1.0|\n",
      "|released|  male|     20|              0|              1|      16|   Seoul|       1/30/20|(85,[1,3,4,6,75],...|  1.0|\n",
      "|released|female|     20|              1|              0|      24|   Seoul|       1/31/20|(85,[1,2,4,6,72],...|  0.0|\n",
      "|released|female|     50|              1|              0|      19|   Seoul|       1/31/20|(85,[1,2,4,6,72],...|  0.0|\n",
      "|released|  male|     20|              1|              0|      10|   Seoul|       1/31/20|(85,[1,2,4,6,72],...|  1.0|\n",
      "|released|  male|     20|              0|              0|      22|   Seoul|        2/2/20|(85,[1,4,6,73],[2...|  1.0|\n",
      "|released|  male|     30|              0|              0|      16|   Seoul|        2/5/20|(85,[1,4,6,71],[3...|  1.0|\n",
      "|released|female|     60|              1|              0|      24|   Seoul|        2/5/20|(85,[1,2,4,6,71],...|  0.0|\n",
      "|released|female|     50|              0|              0|      23|   Seoul|        2/6/20|(85,[1,4,6,77],[5...|  0.0|\n",
      "|released|  male|     20|              0|              0|      20|   Seoul|        2/7/20|(85,[1,4,6,83],[2...|  1.0|\n",
      "|released|  male|     80|              1|              0|     100|   Seoul|       2/16/20|(85,[1,2,4,6,76],...|  1.0|\n",
      "|released|female|     60|              1|              1|      25|   Seoul|       2/16/20|(85,[1,2,3,4,6,76...|  0.0|\n",
      "|isolated|  male|     70|              0|              1|     100|   Seoul|       2/19/20|(85,[0,1,3,4,6,67...|  1.0|\n",
      "|released|  male|     70|              1|              0|      21|   Seoul|       2/19/20|(85,[1,2,4,6,67],...|  1.0|\n",
      "|released|  male|     70|              1|              0|      10|   Seoul|       2/20/20|(85,[1,2,4,6,65],...|  1.0|\n",
      "|isolated|  male|     20|              0|              0|     100|   Seoul|       2/20/20|(85,[0,1,4,6,65],...|  1.0|\n",
      "|released|female|     70|              1|              0|      17|   Seoul|       2/20/20|(85,[1,2,4,6,65],...|  0.0|\n",
      "|isolated|female|     70|              0|              0|     100|   Seoul|       2/20/20|(85,[0,1,4,6,65],...|  0.0|\n",
      "|released|  male|     80|              1|              0|      17|   Seoul|       2/20/20|(85,[1,2,4,6,65],...|  1.0|\n",
      "|isolated|  male|     30|              0|              0|     100|   Seoul|       2/21/20|(85,[0,1,4,6,61],...|  1.0|\n",
      "|isolated|  male|     50|              0|              0|     100|   Seoul|       2/21/20|(85,[0,1,4,6,61],...|  1.0|\n",
      "|released|  male|     40|              1|              0|      21|   Seoul|       2/22/20|(85,[1,2,4,6,45],...|  1.0|\n",
      "|isolated|  male|     60|              0|              0|     100|   Seoul|       2/22/20|(85,[0,1,4,6,45],...|  1.0|\n",
      "|released|  male|     30|              0|              1|      18|   Seoul|       2/22/20|(85,[1,3,4,6,45],...|  1.0|\n",
      "|released|  male|     50|              0|              0|      10|   Seoul|       2/23/20|(85,[1,4,6,36],[5...|  1.0|\n",
      "|released|female|     70|              0|              0|      17|   Seoul|       2/23/20|(85,[1,4,6,36],[7...|  0.0|\n",
      "|released|female|     20|              0|              1|      14|   Seoul|       2/26/20|(85,[1,3,4,6,24],...|  0.0|\n",
      "|released|  male|     60|              0|              0|     100|   Seoul|       2/23/20|(85,[1,4,6,36],[6...|  1.0|\n",
      "+--------+------+-------+---------------+---------------+--------+--------+--------------+--------------------+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "# This sets up the data to run through the model.   \n",
    "# The columns \"features\" and \"label\" are added to the existing data set.\n",
    "# These columns provide the data (vectors and label) needed for processing the data\n",
    "# \n",
    "\n",
    "supervised = RFormula(formula=\"sex ~ .\")\n",
    "fittedRF = supervised.fit(covid)\n",
    "preparedDF = fittedRF.transform(covid)\n",
    "print()\n",
    "print(\"DATA AFTER FITTING:\")\n",
    "preparedDF.show(30)\n",
    "\n",
    "# \n",
    "# Split the data into a Training set (70%) and Test data (30%)\n",
    "# Set up and run the logistic regression \n",
    "# \n",
    "\n",
    "trainingData, testData = preparedDF.randomSplit([0.7, 0.3], 5) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients = [0.48813715612913067,-0.01156125684120185,0.06827504191074643,0.040397943773924985,-0.004670340175240567,1.109856938984425,1.116841579428748,0.9934568922486144,0.6174768563200163,1.5665811476137084,1.586331687847308,0.9088678448524021,1.800289575739157,1.0580580311480192,1.1295938456376662,0.7036641221901972,1.3035907296482518,1.405249804956088,2.404436080994301,1.0243014046426577,-0.26611154623212396,7.19711170318372,7.799386756409984,8.179455558602875,8.553973396524936,7.633728696608021,8.462282851575846,8.336203490763504,8.39416535188146,7.6380992157770775,7.4264988350008965,8.188435434759453,7.8627815244609955,7.956624131911796,7.303031805819307,8.301209067916739,7.564513860144862,7.266512543278602,7.835665139507113,7.650338762059154,7.833607707649667,8.68919842510396,8.492291293559147,7.99358441447382,7.726064898079559,8.371567407155949,8.097855496290128,8.554228460346438,7.549061337619632,7.542781105409881,8.637033463527999,8.079443434842627,8.346302465946868,8.774548330146466,8.730721993243856,7.339280276204557,8.724414451200817,8.040154474030206,7.82732619127102,7.919956857580576,7.787365199837157,8.332222248922271,8.00096388150526,8.592269195048724,7.688218587431811,8.871036985889402,8.121371059122483,9.04509793625346,7.703864425369972,7.475067590677946,7.148976885586872,7.621220498719899,-44.98621815472684,45.21719437273741,7.696572027946022,44.54395653852793,8.79444230169066,44.14213666699233,-43.86644776192972,0.0,0.0,44.26256731600461,44.76443280839737,43.70331009652504,44.228913388006205]\n",
      "Y intercept = -8.898427928692161\n",
      "\n",
      "areaUnderROC: 0.6641888654231812\n",
      "\n",
      "ROC Values\n",
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|0.003567181926278...|0.025373134328358207|\n",
      "|0.009512485136741973| 0.03880597014925373|\n",
      "|0.013079667063020214| 0.05223880597014925|\n",
      "|0.014268727705112961| 0.07164179104477612|\n",
      "|0.016646848989298454| 0.08656716417910448|\n",
      "|0.022592152199762187| 0.09850746268656717|\n",
      "|0.030915576694411414| 0.11194029850746269|\n",
      "|0.039239001189060645|  0.1208955223880597|\n",
      "| 0.04280618311533888|  0.1373134328358209|\n",
      "| 0.04994054696789536| 0.14776119402985075|\n",
      "|0.059453032104637336| 0.15522388059701492|\n",
      "| 0.06896551724137931| 0.16567164179104477|\n",
      "| 0.07728894173602854|  0.1865671641791045|\n",
      "| 0.08085612366230678|                 0.2|\n",
      "| 0.09036860879904875|   0.208955223880597|\n",
      "| 0.09869203329369798| 0.22238805970149253|\n",
      "| 0.10582639714625446| 0.23582089552238805|\n",
      "|  0.1117717003567182| 0.24925373134328357|\n",
      "| 0.11890606420927467|  0.2582089552238806|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lrModel = lr.fit(trainingData)\n",
    "displaySummary = lrModel.summary\n",
    "\n",
    "#\n",
    "# To get the parameters associated with the model, un-comment the \"explainParams\" below. \n",
    "# \n",
    "# print(lr.explainParams())\n",
    "\n",
    "#\n",
    "# Get the resulting coefficients and Y intercept \n",
    "# \n",
    "\n",
    "print (\"Coefficients = \" + str(lrModel.coefficients))\n",
    "print (\"Y intercept = \" + str(lrModel.intercept)) \n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "#\n",
    "# Obtain the ROC using the \"AREA UNDER THE CURVE\"\n",
    "# \n",
    "print(\"\")\n",
    "print(\"areaUnderROC: \" + str(displaySummary.areaUnderROC))\n",
    "print(\"\")\n",
    "print('ROC Values')\n",
    "displaySummary.roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION Cross Validation with TEST Data Part 2\n",
    "\n",
    "Now we will run the Logistic Regression with the Test data set and review the evaluation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+---------------+---------------+--------+-----------------+--------------+--------------------+-----+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|         province|confirmed_date|            features|label|\n",
      "+--------+------+-------+---------------+---------------+--------+-----------------+--------------+--------------------+-----+\n",
      "|isolated|female|      0|              1|              1|     100|            Seoul|        3/8/20|(85,[0,2,3,4,6,55...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|          Daejeon|       3/30/20|(85,[0,1,4,14,43]...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|          Gwangju|       3/31/20|(85,[0,1,4,17,25]...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|      Gyeonggi-do|       3/26/20|(85,[0,1,4,5,44],...|  0.0|\n",
      "|isolated|female|     10|              0|              0|     100|            Seoul|       3/23/20|(85,[0,1,4,6,63],...|  0.0|\n",
      "|isolated|female|     10|              0|              1|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,3,4,7,24...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|       2/29/20|(85,[0,1,2,4,5,28...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|       3/10/20|(85,[0,1,2,4,5,21...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|       3/15/20|(85,[0,1,2,4,5,57...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|        3/3/20|(85,[0,1,2,4,5,47...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|        3/4/20|(85,[0,1,2,4,5,38...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|      Gyeonggi-do|        3/6/20|(85,[0,1,2,4,5,30...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100| Gyeongsangbuk-do|       3/29/20|(85,[0,1,2,4,7,39...|  0.0|\n",
      "|isolated|female|     10|              1|              0|     100|            Seoul|        3/4/20|(85,[0,1,2,4,6,38...|  0.0|\n",
      "|isolated|female|     10|              1|              1|     100|            Seoul|       3/15/20|(85,[0,1,2,3,4,6,...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Busan|       3/18/20|(85,[0,1,4,9,35],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       Gangwon-do|        3/8/20|(85,[0,1,4,16,55]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|      Gyeonggi-do|       3/28/20|(85,[0,1,4,5,26],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|      Gyeonggi-do|        3/6/20|(85,[0,1,4,5,30],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|      Gyeonggi-do|        4/1/20|(85,[0,1,4,5,48],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,4,7,24],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,4,7,24],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       2/29/20|(85,[0,1,4,7,28],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       3/18/20|(85,[0,1,4,7,35],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|       3/30/20|(85,[0,1,4,7,43],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangbuk-do|        3/4/20|(85,[0,1,4,7,38],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100| Gyeongsangnam-do|       2/24/20|(85,[0,1,4,10,53]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|          Incheon|       3/25/20|(85,[0,1,4,11,46]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|          Incheon|       3/27/20|(85,[0,1,4,11,41]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|          Incheon|        4/3/20|(85,[0,1,4,11,62]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|     Jeollabuk-do|       3/28/20|(85,[0,1,4,18,26]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|     Jeollabuk-do|       3/29/20|(85,[0,1,4,18,39]...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/10/20|(85,[0,1,4,6,21],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/10/20|(85,[0,1,4,6,21],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/11/20|(85,[0,1,4,6,42],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/11/20|(85,[0,1,4,6,42],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/17/20|(85,[0,1,4,6,54],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/23/20|(85,[0,1,4,6,63],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/24/20|(85,[0,1,4,6,33],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/25/20|(85,[0,1,4,6,46],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/28/20|(85,[0,1,4,6,26],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/29/20|(85,[0,1,4,6,39],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/29/20|(85,[0,1,4,6,39],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/30/20|(85,[0,1,4,6,43],...|  0.0|\n",
      "|isolated|female|     20|              0|              0|     100|            Seoul|       3/31/20|(85,[0,1,4,6,25],...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Busan|       3/31/20|(85,[0,1,3,4,9,25...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|       3/22/20|(85,[0,1,3,4,5,59...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|       3/30/20|(85,[0,1,3,4,5,43...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|       3/31/20|(85,[0,1,3,4,5,25...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|      Gyeonggi-do|        4/4/20|(85,[0,1,3,4,5,64...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       2/28/20|(85,[0,1,3,4,6,22...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       3/11/20|(85,[0,1,3,4,6,42...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       3/13/20|(85,[0,1,3,4,6,58...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|       3/25/20|(85,[0,1,3,4,6,46...|  0.0|\n",
      "|isolated|female|     20|              0|              1|     100|            Seoul|        3/8/20|(85,[0,1,3,4,6,55...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/10/20|(85,[0,1,2,4,5,21...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/14/20|(85,[0,1,2,4,5,60...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/16/20|(85,[0,1,2,4,5,37...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/16/20|(85,[0,1,2,4,5,37...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/16/20|(85,[0,1,2,4,5,37...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/24/20|(85,[0,1,2,4,5,33...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|       3/31/20|(85,[0,1,2,4,5,25...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|      Gyeonggi-do|        4/4/20|(85,[0,1,2,4,5,64...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       2/23/20|(85,[0,1,2,4,7,36...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       2/28/20|(85,[0,1,2,4,7,22...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       2/29/20|(85,[0,1,2,4,7,28...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|       3/29/20|(85,[0,1,2,4,7,39...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|        3/5/20|(85,[0,1,2,4,7,34...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100| Gyeongsangbuk-do|        3/6/20|(85,[0,1,2,4,7,30...|  0.0|\n",
      "|isolated|female|     20|              1|              0|     100|            Seoul|       3/10/20|(85,[0,1,2,4,6,21...|  0.0|\n",
      "|isolated|female|     20|              1|              1|     100|      Gyeonggi-do|       3/23/20|(85,[0,1,2,3,4,5,...|  0.0|\n",
      "|isolated|female|     20|              1|              1|     100|      Gyeonggi-do|       3/26/20|(85,[0,1,2,3,4,5,...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|Chungcheongnam-do|       3/19/20|(85,[0,1,4,8,40],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|       3/28/20|(85,[0,1,4,5,26],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|       3/30/20|(85,[0,1,4,5,43],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|        3/6/20|(85,[0,1,4,5,30],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|      Gyeonggi-do|        3/9/20|(85,[0,1,4,5,29],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|       2/25/20|(85,[0,1,4,7,31],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|       2/26/20|(85,[0,1,4,7,24],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|        3/2/20|(85,[0,1,4,7,56],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100| Gyeongsangbuk-do|       3/30/20|(85,[0,1,4,7,43],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|          Incheon|       3/28/20|(85,[0,1,4,11,26]...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|        3/1/20|(85,[0,1,4,6,27],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/10/20|(85,[0,1,4,6,21],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/19/20|(85,[0,1,4,6,40],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/27/20|(85,[0,1,4,6,41],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|       3/31/20|(85,[0,1,4,6,25],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|        3/9/20|(85,[0,1,4,6,29],...|  0.0|\n",
      "|isolated|female|     30|              0|              0|     100|            Seoul|        4/1/20|(85,[0,1,4,6,48],...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|Chungcheongnam-do|       2/27/20|(85,[0,1,3,4,8,23...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|      Gyeonggi-do|       3/19/20|(85,[0,1,3,4,5,40...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|      Gyeonggi-do|       3/27/20|(85,[0,1,3,4,5,41...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100| Gyeongsangnam-do|       3/31/20|(85,[0,1,3,4,10,2...|  0.0|\n",
      "|isolated|female|     30|              0|              1|     100|           Sejong|       3/12/20|(85,[0,1,3,4,12,5...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|       2/28/20|(85,[0,1,2,4,5,22...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|       3/15/20|(85,[0,1,2,4,5,57...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|       3/20/20|(85,[0,1,2,4,5,32...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|        4/2/20|(85,[0,1,2,4,5,51...|  0.0|\n",
      "|isolated|female|     30|              1|              0|     100|      Gyeonggi-do|        4/3/20|(85,[0,1,2,4,5,62...|  0.0|\n",
      "|isolated|female|     40|              0|              0|     100|Chungcheongbuk-do|       3/13/20|(85,[0,1,4,13,58]...|  0.0|\n",
      "+--------+------+-------+---------------+---------------+--------+-----------------+--------------+--------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n",
      "+--------+------+-------+---------------+---------------+--------+----------------+--------------+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|        province|confirmed_date|\n",
      "+--------+------+-------+---------------+---------------+--------+----------------+--------------+\n",
      "|isolated|female|      0|              1|              1|     100|           Seoul|        3/8/20|\n",
      "|isolated|female|     10|              0|              0|     100|         Daejeon|       3/30/20|\n",
      "|isolated|female|     10|              0|              0|     100|         Gwangju|       3/31/20|\n",
      "|isolated|female|     10|              0|              0|     100|     Gyeonggi-do|       3/26/20|\n",
      "|isolated|female|     10|              0|              0|     100|           Seoul|       3/23/20|\n",
      "|isolated|female|     10|              0|              1|     100|Gyeongsangbuk-do|       2/26/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|       2/29/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|       3/10/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|       3/15/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|        3/3/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|        3/4/20|\n",
      "|isolated|female|     10|              1|              0|     100|     Gyeonggi-do|        3/6/20|\n",
      "|isolated|female|     10|              1|              0|     100|Gyeongsangbuk-do|       3/29/20|\n",
      "|isolated|female|     10|              1|              0|     100|           Seoul|        3/4/20|\n",
      "|isolated|female|     10|              1|              1|     100|           Seoul|       3/15/20|\n",
      "|isolated|female|     20|              0|              0|     100|           Busan|       3/18/20|\n",
      "|isolated|female|     20|              0|              0|     100|      Gangwon-do|        3/8/20|\n",
      "|isolated|female|     20|              0|              0|     100|     Gyeonggi-do|       3/28/20|\n",
      "|isolated|female|     20|              0|              0|     100|     Gyeonggi-do|        3/6/20|\n",
      "|isolated|female|     20|              0|              0|     100|     Gyeonggi-do|        4/1/20|\n",
      "+--------+------+-------+---------------+---------------+--------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# RUN THE TEST DATA \n",
    "# \n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "testData.show(100)\n",
    "predictions = lrModel.transform(testData)\n",
    "testDF = predictions\n",
    "\n",
    "#\n",
    "# Create the testDF for output to a CSV file for later comparison. \n",
    "#\n",
    "testDF = testDF.select(\"state\", \"sex\", \"Rev_Age\", \"Patient_Contact\", \"Have_Onset_Date\", \"Duration\", \"province\", 'confirmed_date')\n",
    "\n",
    "testDF.show()\n",
    "\n",
    "\n",
    "#\n",
    "# Create an Evaluator for binary classification, which expects two input columns: rawPrediction and label.\n",
    "# Evaluates predictions and returns a scalar metric areaUnderROC(larger is better but < 1).\n",
    "#\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\\\n",
    "  .setLabelCol(\"label\")\\\n",
    "  .setRawPredictionCol(\"rawPrediction\")\\\n",
    "  .setMetricName(\"areaUnderROC\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Confusion Matrix Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truePos =  72\n",
      "falsePos =  160\n",
      "trueNeg =  316\n",
      "falseNeg =  123\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                   Predicted\n",
      "                Y=1    |   Y=0\n",
      " Actual   y=1   72        123\n",
      "          y=0   160         316\n",
      "Test Error = 0.421759 \n",
      "Accuracy = 0.578241 \n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "#print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "#print(\"Accuracy = %g \" % accuracy)\n",
    "\n",
    "\n",
    "#\n",
    "# Obtain data to build Confusion Matrix \n",
    "#\n",
    "\n",
    "truePos = predictions.select(\"state\").where(\"state = 'released' AND prediction = 1\").count()\n",
    "falsePos = predictions.select(\"state\").where(\"state = 'isolated' AND prediction = 1\").count()\n",
    "trueNeg = predictions.select(\"state\").where(\"state = 'isolated' AND prediction = 0\").count()\n",
    "falseNeg = predictions.select(\"state\").where(\"state = 'released' AND prediction = 0\").count()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"truePos = \", truePos )\n",
    "print(\"falsePos = \", falsePos )\n",
    "print(\"trueNeg = \", trueNeg )\n",
    "print(\"falseNeg = \", falseNeg)\n",
    "\n",
    "print() \n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"                   Predicted\")\n",
    "print(\"                Y=1    |   Y=0\")\n",
    "print(\" Actual   y=1   \" + str(truePos) + \"        \" + str(falseNeg))\n",
    "print(\"          y=0   \" + str(falsePos) + \"         \" + str(trueNeg)) \n",
    "\n",
    "#\n",
    "# To get the parameters associated with the model, un-comment the \"explainParams\" below. \n",
    "# \n",
    "# print(lr.explainParams())\n",
    "\n",
    "\n",
    "print(\"Test Error = %g \" % ((falsePos+falseNeg)/(falsePos+falseNeg+truePos+trueNeg)))\n",
    "print(\"Accuracy = %g \" % ((truePos+trueNeg)/(falsePos+falseNeg+truePos+trueNeg)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCISION TREE - Test Data Part 2\n",
    "The actual execution of the Decision Tree model is relatively straightforward.   There is a little prep required for the data so that we will have a label and vectors **indexed**.  \n",
    "* Similar to Logistic Regresion, the data is read in and the \"label\" and \"features\" columns are created. \n",
    "* The data is then converted into Indexes needed for the Decision Tree model to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREDICTIONS DATA:\n",
      "+--------+------+-------+---------------+---------------+--------+----------+\n",
      "|   state|   sex|Rev_Age|Patient_Contact|Have_Onset_Date|Duration|prediction|\n",
      "+--------+------+-------+---------------+---------------+--------+----------+\n",
      "|isolated|female|      0|              1|              0|     100|       1.0|\n",
      "|isolated|female|      0|              1|              0|     100|       1.0|\n",
      "|isolated|female|      0|              1|              0|     100|       1.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              0|              0|     100|       0.0|\n",
      "|isolated|female|     10|              1|              0|     100|       1.0|\n",
      "|isolated|female|     10|              1|              0|     100|       1.0|\n",
      "|isolated|female|     10|              1|              0|     100|       1.0|\n",
      "|isolated|female|     10|              1|              0|     100|       1.0|\n",
      "|isolated|female|     10|              1|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       0.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "|isolated|female|     20|              0|              0|     100|       1.0|\n",
      "+--------+------+-------+---------------+---------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(preparedDF)\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(preparedDF)\n",
    "(trainingDataDT, testDataDT) = preparedDF.randomSplit([0.7, 0.3])\n",
    "\n",
    "# print(\"AFTER INDEXING:\")\n",
    "#\n",
    "# Create a decision tree classifier that will process the columns created above and run the model. \n",
    "# \n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "modelDT = pipeline.fit(trainingDataDT)\n",
    "\n",
    "# Make predictions.\n",
    "predictionsDT = modelDT.transform(testDataDT)\n",
    "\n",
    "print()\n",
    "print(\"PREDICTIONS DATA:\")\n",
    "#predictions.select('sex', 'Rev_Age', 'Patient_Contact', 'Have_Onset_Date', 'Duration', 'rawPrediction', 'prediction', 'probability').show()\n",
    "\n",
    "testDFdt = predictionsDT.select(\"state\", \"sex\", \"Rev_Age\", \"Patient_Contact\", \"Have_Onset_Date\", \"Duration\", \"prediction\")\n",
    "testDFdt.show()\n",
    "\n",
    "\n",
    "\n",
    "testDFdt.write.format(\"csv\").mode('overwrite')\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".save(\"decision_tree_dataframe_part2.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Confusion Matrix Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truePos =  89\n",
      "falsePos =  182\n",
      "trueNeg =  271\n",
      "falseNeg =  122\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "                   Predicted\n",
      "                Y=1    |   Y=0\n",
      " Actual   y=1   89        122\n",
      "          y=0   182         271\n",
      "Test Error = 0.457831 \n",
      "Accuracy = 0.542169 \n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsDT)\n",
    "#print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "#print(\"Accuracy = %g \" % accuracy)\n",
    "\n",
    "truePosDT = predictionsDT.select(\"state\").where(\"state = 'released' AND prediction = 1\").count()\n",
    "falsePosDT = predictionsDT.select(\"state\").where(\"state = 'isolated' AND prediction = 1\").count()\n",
    "trueNegDT = predictionsDT.select(\"state\").where(\"state = 'isolated' AND prediction = 0\").count()\n",
    "falseNegDT = predictionsDT.select(\"state\").where(\"state = 'released' AND prediction = 0\").count()\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"truePos = \", truePosDT )\n",
    "print(\"falsePos = \", falsePosDT )\n",
    "print(\"trueNeg = \", trueNegDT )\n",
    "print(\"falseNeg = \", falseNegDT)\n",
    "\n",
    "print() \n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"                   Predicted\")\n",
    "print(\"                Y=1    |   Y=0\")\n",
    "print(\" Actual   y=1   \" + str(truePosDT) + \"        \" + str(falseNegDT))\n",
    "print(\"          y=0   \" + str(falsePosDT) + \"         \" + str(trueNegDT)) \n",
    "\n",
    "\n",
    "print(\"Test Error = %g \" % ((falsePosDT+falseNegDT)/(falsePosDT+falseNegDT+truePosDT+trueNegDT)))\n",
    "print(\"Accuracy = %g \" % ((truePosDT+trueNegDT)/(falsePosDT+falseNegDT+truePosDT+trueNegDT)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the Logistic Regression and the Decision Tree multiple times for part 2 of this project where I switched the response variable to 'sex' variable. I had both situations where Logistic Regression was better and where Decision Tree was better. This leads to the conclusion that there is a very different outcome depending on the test data. In addition the accuracy of these for all the times we tried was between 50% and 65%. This means that you relatively get the same results with random guessing as there is only possible responses for 'sex'. With these predictors, there is not a strong prediciton method to predict the 'sex' variable. To predict the 'sex' variable I believe that the predictors should be more quantitative predictors such as heart rate, blood pressure, breathing rate, oxygen saturation, transmisiblity, and servity of symptoms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
